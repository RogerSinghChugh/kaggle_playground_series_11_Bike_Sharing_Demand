{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf28097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e088e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(data=r\"resources\\bike-sharing-demand\\train.csv\")\n",
    "test_data = TabularDataset(data=r\"resources\\bike-sharing-demand\\test.csv\")\n",
    "submission = pd.read_csv(r\"resources\\bike-sharing-demand\\sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb49250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic feature engineering\n",
    "train_data['datetime'] = pd.to_datetime(train_data['datetime'])\n",
    "test_data['datetime'] = pd.to_datetime(test_data['datetime'])\n",
    "\n",
    "train_data['hour'] = train_data['datetime'].dt.hour\n",
    "train_data['dayofweek'] = train_data['datetime'].dt.dayofweek\n",
    "train_data['month'] = train_data['datetime'].dt.month\n",
    "train_data['is_rush_hour'] = train_data['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
    "train_data['is_rush_hour'] = (train_data['is_rush_hour'] & (train_data['workingday'] == 1)).astype(int)\n",
    "\n",
    "test_data['hour'] = test_data['datetime'].dt.hour\n",
    "test_data['dayofweek'] = test_data['datetime'].dt.dayofweek\n",
    "test_data['month'] = test_data['datetime'].dt.month\n",
    "test_data['is_rush_hour'] = test_data['hour'].isin([7, 8, 9, 16, 17, 18, 19])\n",
    "test_data['is_rush_hour'] = (test_data['is_rush_hour'] & (test_data['workingday'] == 1)).astype(int)\n",
    "\n",
    "\n",
    "train_data['casual_log'] = np.log1p(train_data['casual'])\n",
    "train_data['registered_log'] = np.log1p(train_data['registered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d370ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build 2 models, one for casual and one for registered, then we can sum the predictions to get the count\n",
    "# we will first drop some columns\n",
    "\n",
    "casual_train_data = train_data.copy()\n",
    "registered_train_data = train_data.copy()\n",
    "\n",
    "casual_train_data.drop(columns=['count', 'registered', 'casual', 'datetime', 'atemp', 'registered_log'], inplace=True)\n",
    "registered_train_data.drop(columns=['count', 'registered', 'casual', 'datetime', 'atemp', 'casual_log'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5244b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "casual_label = \"casual_log\"\n",
    "registered_label = \"registered_log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7f644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          16\n",
      "Pytorch Version:    2.9.1+cpu\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       1.00 GB / 7.36 GB (13.6%)\n",
      "Disk Space Avail:   27.03 GB / 475.83 GB (5.7%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2026-02-15 17:56:44,865\tINFO worker.py:2014 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\ray\\_private\\worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t\tContext path: \"c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\casual_1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Beginning AutoGluon training ... Time limit = 137s\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m AutoGluon will save models to \"c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\casual_1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Train Data Rows:    9676\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Train Data Columns: 11\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Label Column:       casual_log\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tAvailable Memory:                    1603.36 MB\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.70 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\t('float', []) : 2 | ['temp', 'windspeed']\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\t('int', [])   : 9 | ['season', 'holiday', 'workingday', 'weather', 'humidity', ...]\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\t('float', [])     : 2 | ['temp', 'windspeed']\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\t('int', [])       : 6 | ['season', 'weather', 'humidity', 'hour', 'dayofweek', ...]\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t\t('int', ['bool']) : 3 | ['holiday', 'workingday', 'is_rush_hour']\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t11 features in original data used to generate 11 features in processed data.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.51 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 91.48s of the 137.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.64%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=27916)\u001b[0m [1000]\tvalid_set's rmse: 0.51143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t-0.4835\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t8.61s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t1.25s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 69.07s of the 114.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=20568)\u001b[0m [1000]\tvalid_set's rmse: 0.49494\u001b[32m [repeated 17x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t-0.4784\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t3.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.33s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 56.79s of the 102.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/0.9 GB\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 184 due to low memory. Expected memory usage reduced from 24.36% -> 15.0% of available memory...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t-0.4988\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t1.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 54.21s of the 99.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.56% memory usage per fold, 70.24%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=17.56%)\n",
      "\u001b[36m(_ray_fit pid=18500)\u001b[0m \tRan out of time, early stopping on iteration 3141.\n",
      "\u001b[36m(_ray_fit pid=12032)\u001b[0m \tRan out of time, early stopping on iteration 3798.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t-0.4745\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t43.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 7.56s of the 53.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.0/1.7 GB\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t-0.4879\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t1.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5.46s of the 51.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.37%)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 137.25s of the -391.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/1.1 GB\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.364, 'ExtraTreesMSE_BAG_L1': 0.227, 'LightGBMXT_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.182, 'RandomForestMSE_BAG_L1': 0.045}\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t-0.468\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 137.25s of the -392.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/1.1 GB\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.364, 'ExtraTreesMSE_BAG_L1': 0.227, 'LightGBMXT_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.182, 'RandomForestMSE_BAG_L1': 0.045}\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t-0.468\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m AutoGluon training complete, total runtime = 529.51s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 700.8 rows/s (1210 batch size)\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\casual_1\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=18904)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         CatBoost_BAG_L1      -0.483639  -0.474484  root_mean_squared_error        1.260636       0.038017  43.039255                 1.260636                0.038017          43.039255            1       True          4\n",
      "1     WeightedEnsemble_L3      -0.484172  -0.468032  root_mean_squared_error        3.688891       2.530522  58.148010                 0.024009                0.000000           0.009870            3       True          7\n",
      "2     WeightedEnsemble_L2      -0.484172  -0.468032  root_mean_squared_error        3.689916       2.531798  58.152993                 0.025033                0.001276           0.014853            2       True          6\n",
      "3         LightGBM_BAG_L1      -0.486703  -0.478400  root_mean_squared_error        0.391738       0.326210   3.502486                 0.391738                0.326210           3.502486            1       True          2\n",
      "4       LightGBMXT_BAG_L1      -0.494003  -0.483454  root_mean_squared_error        1.047886       1.247207   8.607515                 1.047886                1.247207           8.607515            1       True          1\n",
      "5    ExtraTreesMSE_BAG_L1      -0.507710  -0.487928  root_mean_squared_error        0.554136       0.462220   1.190402                 0.554136                0.462220           1.190402            1       True          5\n",
      "6  RandomForestMSE_BAG_L1      -0.525276  -0.498809  root_mean_squared_error        0.410488       0.456868   1.798481                 0.410488                0.456868           1.798481            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t552s\t = DyStack   runtime |\t48s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 48s\n",
      "AutoGluon will save models to \"c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\casual_1\"\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 11\n",
      "Label Column:       casual_log\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1088.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.79 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2 | ['temp', 'windspeed']\n",
      "\t\t('int', [])   : 9 | ['season', 'holiday', 'workingday', 'weather', 'humidity', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 2 | ['temp', 'windspeed']\n",
      "\t\t('int', [])       : 6 | ['season', 'weather', 'humidity', 'hour', 'dayofweek', ...]\n",
      "\t\t('int', ['bool']) : 3 | ['holiday', 'workingday', 'is_rush_hour']\n",
      "\t0.1s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.57 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 32.08s of the 48.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.44%)\n",
      "\t-1.4496\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.99s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 17.27s of the 33.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=3.83%)\n",
      "\t-0.478\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.32s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 0.88s of the 16.87s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/1.4 GB\n",
      "\t-0.4973\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.93s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 48.14s of the 12.76s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/2.6 GB\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.706, 'RandomForestMSE_BAG_L1': 0.294}\n",
      "\t-0.4738\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 12.70s of the 12.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.83%)\n",
      "\t-0.4786\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.44s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3.16s of the 3.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.72%)\n",
      "\t-0.4785\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 48.14s of the -8.38s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=16, gpus=0, mem=0.0/1.1 GB\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.556, 'RandomForestMSE_BAG_L1': 0.222, 'LightGBMXT_BAG_L2': 0.111, 'LightGBM_BAG_L2': 0.111}\n",
      "\t-0.4736\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 56.88s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2242.8 rows/s (1361 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\casual_1\")\n"
     ]
    }
   ],
   "source": [
    "# build casual model\n",
    "casual_predictor = TabularPredictor(label=casual_label, problem_type='regression', path=\"casual_1\").fit(casual_train_data, presets=\"best\", time_limit=60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf11c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'best' maps to 'best_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.11.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26200\n",
      "CPU Count:          16\n",
      "Pytorch Version:    2.9.1+cpu\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       1.77 GB / 7.36 GB (24.0%)\n",
      "Disk Space Avail:   19.22 GB / 475.83 GB (4.0%)\n",
      "===================================================\n",
      "Presets specified: ['best']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\registered_1\\ds_sub_fit\\sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3      -0.321920  -0.325769  root_mean_squared_error        5.338429      15.684017  91.432661                 0.016285                0.000998           0.034400            3       True         11\n",
      "1      WeightedEnsemble_L2      -0.322057  -0.326237  root_mean_squared_error        3.971261      14.276900  74.220051                 0.021891                0.000999           0.010286            2       True          5\n",
      "2          CatBoost_BAG_L2      -0.322075  -0.328672  root_mean_squared_error        4.686810      14.940401  88.068501                 0.192256                0.042070          12.094207            2       True          9\n",
      "3        LightGBMXT_BAG_L2      -0.322258  -0.332785  root_mean_squared_error        4.769583      14.981274  78.437730                 0.275029                0.082944           2.463435            2       True          6\n",
      "4          LightGBM_BAG_L2      -0.324993  -0.329506  root_mean_squared_error        4.737516      14.936289  77.712450                 0.242962                0.037958           1.738155            2       True          7\n",
      "5     ExtraTreesMSE_BAG_L2      -0.326339  -0.332190  root_mean_squared_error        4.886925      15.602990  77.565900                 0.392371                0.704660           1.591605            2       True         10\n",
      "6          CatBoost_BAG_L1      -0.326451  -0.329464  root_mean_squared_error        1.390514       0.042783  53.040216                 1.390514                0.042783          53.040216            1       True          4\n",
      "7   RandomForestMSE_BAG_L2      -0.327585  -0.336994  root_mean_squared_error        4.743914      15.817594  78.280174                 0.249360                0.919264           2.305879            2       True          8\n",
      "8          LightGBM_BAG_L1      -0.327857  -0.335950  root_mean_squared_error        0.703536       0.875715   8.452565                 0.703536                0.875715           8.452565            1       True          2\n",
      "9        LightGBMXT_BAG_L1      -0.330988  -0.346194  root_mean_squared_error        1.855319      13.357403  12.716984                 1.855319               13.357403          12.716984            1       True          1\n",
      "10  RandomForestMSE_BAG_L1      -0.375222  -0.379831  root_mean_squared_error        0.545185       0.622430   1.764529                 0.545185                0.622430           1.764529            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t170s\t = DyStack   runtime |\t430s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 430s\n",
      "AutoGluon will save models to \"c:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\registered_1\"\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 11\n",
      "Label Column:       registered_log\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1953.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.79 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2 | ['temp', 'windspeed']\n",
      "\t\t('int', [])   : 9 | ['season', 'holiday', 'workingday', 'weather', 'humidity', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 2 | ['temp', 'windspeed']\n",
      "\t\t('int', [])       : 6 | ['season', 'weather', 'humidity', 'hour', 'dayofweek', ...]\n",
      "\t\t('int', ['bool']) : 3 | ['holiday', 'workingday', 'is_rush_hour']\n",
      "\t0.1s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.57 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 106 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 286.72s of the 430.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.06%)\n",
      "\t-0.3419\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.77s\t = Training   runtime\n",
      "\t14.89s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 260.94s of the 404.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.09%)\n",
      "\t-0.3328\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.33s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 246.90s of the 390.35s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=16, gpus=0, mem=0.1/1.3 GB\n",
      "\t-0.3765\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 243.18s of the 386.63s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.43% memory usage per fold, 73.74%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=18.43%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# build registered model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m registered_predictor = \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mregression\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mregistered_1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregistered_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresets\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m*\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\common\\utils\\decorators.py:34\u001b[39m, in \u001b[36munpack.<locals>._unpack_inner.<locals>._call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(*args, **kwargs):\n\u001b[32m     33\u001b[39m     gargs, gkwargs = g(*other_args, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1412\u001b[39m, in \u001b[36mTabularPredictor.fit\u001b[39m\u001b[34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1409\u001b[39m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m._fit_strategy = fit_strategy\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1418\u001b[39m, in \u001b[36mTabularPredictor._fit\u001b[39m\u001b[34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[39m\n\u001b[32m   1416\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, ag_fit_kwargs: \u001b[38;5;28mdict\u001b[39m, ag_post_fit_kwargs: \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28mself\u001b[39m.save(silent=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_learner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_post_fit_vars()\n\u001b[32m   1420\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_fit(**ag_post_fit_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[39m, in \u001b[36mAbstractTabularLearner.fit\u001b[39m\u001b[34m(self, X, X_val, **kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLearner is already fit.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    158\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_fit_input(X=X, X_val=X_val, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:133\u001b[39m, in \u001b[36mDefaultLearner._fit\u001b[39m\u001b[34m(self, X, X_val, X_test, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, raise_on_model_failure, **trainer_fit_kwargs)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mself\u001b[39m.eval_metric = trainer.eval_metric\n\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.save()\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit_trainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_cleaner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_cleaner\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrainer_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.save_trainer(trainer=trainer)\n\u001b[32m    150\u001b[39m time_end = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:140\u001b[39m, in \u001b[36mAutoTrainer.fit\u001b[39m\u001b[34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, callbacks, label_cleaner, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_cleaner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    138\u001b[39m     core_kwargs[\u001b[33m\"\u001b[39m\u001b[33mlabel_cleaner\u001b[39m\u001b[33m\"\u001b[39m] = label_cleaner\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi_and_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:3345\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi_and_ensemble\u001b[39m\u001b[34m(self, X, y, X_val, y_val, X_test, y_test, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[39m\n\u001b[32m   3343\u001b[39m     \u001b[38;5;28mself\u001b[39m._num_rows_test = \u001b[38;5;28mlen\u001b[39m(X_test)\n\u001b[32m   3344\u001b[39m \u001b[38;5;28mself\u001b[39m._num_cols_train = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(X.columns))\n\u001b[32m-> \u001b[39m\u001b[32m3345\u001b[39m model_names_fit = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_multi_levels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3347\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3350\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel_start\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3357\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3358\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.get_model_names()) == \u001b[32m0\u001b[39m:\n\u001b[32m   3360\u001b[39m     \u001b[38;5;66;03m# TODO v1.0: Add toggle to raise exception if no models trained\u001b[39;00m\n\u001b[32m   3361\u001b[39m     logger.log(\u001b[32m30\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mWarning: AutoGluon did not successfully train any models\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:506\u001b[39m, in \u001b[36mAbstractTabularTrainer.train_multi_levels\u001b[39m\u001b[34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size, callbacks)\u001b[39m\n\u001b[32m    504\u001b[39m         core_kwargs_level[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] = core_kwargs_level.get(\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m, time_limit_core)\n\u001b[32m    505\u001b[39m         aux_kwargs_level[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] = aux_kwargs_level.get(\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m, time_limit_aux)\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     base_model_names, aux_models = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_new_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcore_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43maux_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_suffix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    525\u001b[39m     model_names_fit += base_model_names + aux_models\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.model_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_names_fit) != \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:736\u001b[39m, in \u001b[36mAbstractTabularTrainer.stack_new_level\u001b[39m\u001b[34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001b[39m\n\u001b[32m    734\u001b[39m     core_kwargs[\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m] = core_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) + name_suffix\n\u001b[32m    735\u001b[39m     aux_kwargs[\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m] = aux_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mname_suffix\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) + name_suffix\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m core_models = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_new_level_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m aux_models = []\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_weighted_ensemble:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:887\u001b[39m, in \u001b[36mAbstractTabularTrainer.stack_new_level_core\u001b[39m\u001b[34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, fit_strategy, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[39m\n\u001b[32m    881\u001b[39m fit_kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    882\u001b[39m     num_classes=\u001b[38;5;28mself\u001b[39m.num_classes,\n\u001b[32m    883\u001b[39m     feature_metadata=feature_metadata,\n\u001b[32m    884\u001b[39m )\n\u001b[32m    886\u001b[39m \u001b[38;5;66;03m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:3277\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi\u001b[39m\u001b[34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, delay_bag_sets, **kwargs)\u001b[39m\n\u001b[32m   3275\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_repeat_start == \u001b[32m0\u001b[39m:\n\u001b[32m   3276\u001b[39m     time_start = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3277\u001b[39m     model_names_trained = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi_initial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3279\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeats_initial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_prune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_prune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3286\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3288\u001b[39m     n_repeat_start = n_repeats_initial\n\u001b[32m   3289\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:2872\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi_initial\u001b[39m\u001b[34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[39m\n\u001b[32m   2870\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2871\u001b[39m     time_ratio = hpo_time_ratio \u001b[38;5;28;01mif\u001b[39;00m hpo_enabled \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2872\u001b[39m     models = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_multi_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk_fold_start\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk_fold_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeat_start\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtime_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2882\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2883\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2885\u001b[39m multi_fold_time_elapsed = time.time() - multi_fold_time_start\n\u001b[32m   2886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:3029\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_multi_fold\u001b[39m\u001b[34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, fit_strategy, **kwargs)\u001b[39m\n\u001b[32m   3026\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._callback_early_stop:\n\u001b[32m   3027\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m models_valid\n\u001b[32m-> \u001b[39m\u001b[32m3029\u001b[39m         models_valid += \u001b[43m_detached_train_multi_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_self\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3032\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_limit_model_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit_model_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3039\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3040\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3042\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m fit_strategy == \u001b[33m\"\u001b[39m\u001b[33mparallel\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3043\u001b[39m     models_valid = \u001b[38;5;28mself\u001b[39m._train_multi_fold_parallel(\n\u001b[32m   3044\u001b[39m         X=X,\n\u001b[32m   3045\u001b[39m         y=y,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3052\u001b[39m         **kwargs,\n\u001b[32m   3053\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:4624\u001b[39m, in \u001b[36m_detached_train_multi_fold\u001b[39m\u001b[34m(_self, model, X, y, time_split, time_start, time_limit, time_limit_model_split, hyperparameter_tune_kwargs, is_ray_worker, kwargs)\u001b[39m\n\u001b[32m   4621\u001b[39m         time_start_model=time.time()\n\u001b[32m   4622\u001b[39m         time_left=time_limit-(time_start_model-time_start)\n\u001b[32m-> \u001b[39m\u001b[32m4624\u001b[39m model_name_trained_lst = \u001b[43m_self\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train_single_full\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4626\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4628\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_left\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparameter_tune_kwargs_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4634\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self.low_memory:\n\u001b[32m   4635\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:2645\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_single_full\u001b[39m\u001b[34m(self, X, y, model, X_unlabeled, X_val, y_val, X_test, y_test, X_pseudo, y_pseudo, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, errors, errors_ignore, errors_raise, is_ray_worker, label_cleaner, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m         bagged_model_fit_kwargs = \u001b[38;5;28mself\u001b[39m._get_bagged_model_fit_kwargs(\n\u001b[32m   2642\u001b[39m             k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start\n\u001b[32m   2643\u001b[39m         )\n\u001b[32m   2644\u001b[39m         model_fit_kwargs.update(bagged_model_fit_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m2645\u001b[39m     model_names_trained = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_and_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstack_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2657\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2658\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors_ignore\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors_ignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2660\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors_raise\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors_raise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_ray_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2662\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2663\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2664\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks \u001b[38;5;129;01mand\u001b[39;00m check_callbacks:\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28mself\u001b[39m._callbacks_after_fit(model_names=model_names_trained, stack_name=stack_name, level=level)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:2201\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_and_save\u001b[39m\u001b[34m(self, X, y, model, X_val, y_val, X_test, y_test, X_pseudo, y_pseudo, time_limit, stack_name, level, compute_score, total_resources, errors, errors_ignore, errors_raise, is_ray_worker, **model_fit_kwargs)\u001b[39m\n\u001b[32m   2199\u001b[39m exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2200\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2201\u001b[39m     model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2203\u001b[39m     fit_end_time = time.time()\n\u001b[32m   2204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weight_evaluation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py:2085\u001b[39m, in \u001b[36mAbstractTabularTrainer._train_single\u001b[39m\u001b[34m(self, X, y, model, X_val, y_val, X_test, y_test, total_resources, **model_fit_kwargs)\u001b[39m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train_single\u001b[39m(\n\u001b[32m   2070\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2071\u001b[39m     X: pd.DataFrame,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2079\u001b[39m     **model_fit_kwargs,\n\u001b[32m   2080\u001b[39m ) -> AbstractModel:\n\u001b[32m   2081\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2082\u001b[39m \u001b[33;03m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[32m   2083\u001b[39m \u001b[33;03m    Returns trained model object.\u001b[39;00m\n\u001b[32m   2084\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2085\u001b[39m     model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_resources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2086\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:1125\u001b[39m, in \u001b[36mAbstractModel.fit\u001b[39m\u001b[34m(self, log_resources, log_resources_prefix, **kwargs)\u001b[39m\n\u001b[32m   1123\u001b[39m             torch_cudnn_deterministic_og = torch.backends.cudnn.deterministic\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1127\u001b[39m         out = \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py:270\u001b[39m, in \u001b[36mStackerEnsembleModel._fit\u001b[39m\u001b[34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    269\u001b[39m     time_limit = time_limit - (time.time() - start_time)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:393\u001b[39m, in \u001b[36mBaggedEnsembleModel._fit\u001b[39m\u001b[34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[39m\n\u001b[32m    391\u001b[39m         \u001b[38;5;66;03m# Reserve time for final refit model\u001b[39;00m\n\u001b[32m    392\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] = kwargs[\u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m] * folds_to_fit / (folds_to_fit + \u001b[32m1.2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_folds\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_pseudo\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_pseudo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_pseudo\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_pseudo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_fold_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_fold_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_fold_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_repeat_start\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_repeat_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_bag_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# FIXME: Cleanup self\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m refit_folds:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py:887\u001b[39m, in \u001b[36mBaggedEnsembleModel._fit_folds\u001b[39m\u001b[34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_fit_args \u001b[38;5;129;01min\u001b[39;00m fold_fit_args_list:\n\u001b[32m    886\u001b[39m     fold_fitting_strategy.schedule_fold_model_fit(**fold_fit_args)\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[43mfold_fitting_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_all_folds_scheduled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Do this to maintain model name order based on kfold split regardless of which model finished first in parallel mode\u001b[39;00m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_fit_args \u001b[38;5;129;01min\u001b[39;00m fold_fit_args_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:796\u001b[39m, in \u001b[36mParallelFoldFittingStrategy.after_all_folds_scheduled\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    794\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_pseudo_sequential(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_pseudo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pseudo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_base_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_node_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py:710\u001b[39m, in \u001b[36mParallelFoldFittingStrategy._run_parallel\u001b[39m\u001b[34m(self, X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\u001b[39m\n\u001b[32m    708\u001b[39m unfinished = job_refs\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished:\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     finished, unfinished = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43munfinished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m     finished = finished[\u001b[32m0\u001b[39m]\n\u001b[32m    712\u001b[39m     fold_ctx = job_fold_map.get(finished, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_init_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py:104\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func.\u001b[34m__name__\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33minit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Roger\\Documents\\VSCodeProjects\\kaggle_playground_series_11_Bike_Sharing_Demand\\venv\\Lib\\site-packages\\ray\\_private\\worker.py:3213\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[39m\n\u001b[32m   3211\u001b[39m timeout = timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m10\u001b[39m**\u001b[32m6\u001b[39m\n\u001b[32m   3212\u001b[39m timeout_milliseconds = \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3213\u001b[39m ready_ids, remaining_ids = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3218\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython\\\\ray\\\\_raylet.pyx:3172\u001b[39m, in \u001b[36mray._raylet.CoreWorker.wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython\\\\ray\\\\includes/common.pxi:98\u001b[39m, in \u001b[36mray._raylet.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# build registered model\n",
    "registered_predictor = TabularPredictor(label=registered_label, problem_type='regression', path=\"registered_1\").fit(registered_train_data, presets=\"best\", time_limit=60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cee57034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 10 features using 5000 rows with 5 shuffle sets...\n",
      "\t1259.93s\t= Expected runtime (251.99s per shuffle set)\n",
      "\t677.3s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stddev",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p99_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p99_low",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a5935da4-aa6a-4ad8-8a19-7870e8fbb80a",
       "rows": [
        [
         "hour",
         "1.634821598749856",
         "0.014819169655119733",
         "8.101168766557929e-10",
         "5",
         "1.665334473892439",
         "1.604308723607273"
        ],
        [
         "datetime",
         "0.4546055210508819",
         "0.006384483206197462",
         "4.666929248442103e-09",
         "5",
         "0.46775126021537805",
         "0.4414597818863858"
        ],
        [
         "workingday",
         "0.3059050710611487",
         "0.008310151598015592",
         "6.528946544853013e-08",
         "5",
         "0.323015788059964",
         "0.28879435406233345"
        ],
        [
         "humidity",
         "0.09005507962822776",
         "0.0023409182076416487",
         "5.473967002572438e-08",
         "5",
         "0.09487506257268993",
         "0.08523509668376558"
        ],
        [
         "weather",
         "0.07103525604278507",
         "0.0006185867358926436",
         "6.899918304813201e-10",
         "5",
         "0.0723089346817653",
         "0.06976157740380484"
        ],
        [
         "temp",
         "0.07014386458634574",
         "0.0017511538311643837",
         "4.6575643439936943e-08",
         "5",
         "0.07374951452823128",
         "0.06653821464446019"
        ],
        [
         "atemp",
         "0.04424260562670759",
         "0.0010885150351001296",
         "4.393450644576147e-08",
         "5",
         "0.04648387312885538",
         "0.042001338124559806"
        ],
        [
         "windspeed",
         "0.026911138817948425",
         "0.0013402802768133595",
         "7.358689770104006e-07",
         "5",
         "0.029670794432549188",
         "0.024151483203347663"
        ],
        [
         "season",
         "0.019865513537131434",
         "0.00038407211229017743",
         "1.6757789918163594e-08",
         "5",
         "0.020656323324777633",
         "0.019074703749485236"
        ],
        [
         "holiday",
         "0.009760507082068121",
         "0.0008206970711006705",
         "5.942105341037505e-06",
         "5",
         "0.01145033369470338",
         "0.008070680469432863"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>1.634822</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>8.101169e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>1.665334</td>\n",
       "      <td>1.604309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0.454606</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>4.666929e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.467751</td>\n",
       "      <td>0.441460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>0.305905</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>6.528947e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.323016</td>\n",
       "      <td>0.288794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.090055</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>5.473967e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.094875</td>\n",
       "      <td>0.085235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <td>0.071035</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>6.899918e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.072309</td>\n",
       "      <td>0.069762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.070144</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>4.657564e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>0.066538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>0.044243</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>4.393451e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.042001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>0.026911</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>7.358690e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029671</td>\n",
       "      <td>0.024151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>0.019866</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>1.675779e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020656</td>\n",
       "      <td>0.019075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>5.942105e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.008071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance    stddev       p_value  n  p99_high   p99_low\n",
       "hour          1.634822  0.014819  8.101169e-10  5  1.665334  1.604309\n",
       "datetime      0.454606  0.006384  4.666929e-09  5  0.467751  0.441460\n",
       "workingday    0.305905  0.008310  6.528947e-08  5  0.323016  0.288794\n",
       "humidity      0.090055  0.002341  5.473967e-08  5  0.094875  0.085235\n",
       "weather       0.071035  0.000619  6.899918e-10  5  0.072309  0.069762\n",
       "temp          0.070144  0.001751  4.657564e-08  5  0.073750  0.066538\n",
       "atemp         0.044243  0.001089  4.393451e-08  5  0.046484  0.042001\n",
       "windspeed     0.026911  0.001340  7.358690e-07  5  0.029671  0.024151\n",
       "season        0.019866  0.000384  1.675779e-08  5  0.020656  0.019075\n",
       "holiday       0.009761  0.000821  5.942105e-06  5  0.011450  0.008071"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_predictor.feature_importance(registered_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc99f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 10 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t808.11s\t= Expected runtime (161.62s per shuffle set)\n",
      "\t285.09s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stddev",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "p99_high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p99_low",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a229af9b-cfe9-437f-b0cf-666f38c12813",
       "rows": [
        [
         "hour",
         "1.244050815234084",
         "0.012228074199839851",
         "1.1199666321690492e-09",
         "5",
         "1.2692285890215005",
         "1.2188730414466673"
        ],
        [
         "datetime",
         "0.3257592388528107",
         "0.003622383928480891",
         "1.834427682661486e-09",
         "5",
         "0.3332177774282194",
         "0.31830070027740204"
        ],
        [
         "temp",
         "0.3205233222487961",
         "0.00403970858242074",
         "3.0272680339466625e-09",
         "5",
         "0.3288411380547066",
         "0.3122055064428856"
        ],
        [
         "workingday",
         "0.2066862015253709",
         "0.007071038846284564",
         "1.6413105523374673e-07",
         "5",
         "0.22124556824201375",
         "0.19212683480872805"
        ],
        [
         "humidity",
         "0.13319726937548065",
         "0.0038751760310812705",
         "8.587677467470749e-08",
         "5",
         "0.14117631038410167",
         "0.12521822836685964"
        ],
        [
         "atemp",
         "0.10104965038639901",
         "0.0030985194542455297",
         "1.0595333598334631e-07",
         "5",
         "0.10742954476878058",
         "0.09466975600401745"
        ],
        [
         "weather",
         "0.06082904742314642",
         "0.0032977432250792843",
         "1.0325344322725706e-06",
         "5",
         "0.06761914630323983",
         "0.05403894854305301"
        ],
        [
         "season",
         "0.0409017924719859",
         "0.0009635458047803626",
         "3.693006370635281e-08",
         "5",
         "0.042885746601646964",
         "0.03891783834232484"
        ],
        [
         "windspeed",
         "0.03509168526385544",
         "0.0010876657394619292",
         "1.1060889371358231e-07",
         "5",
         "0.03733120405454566",
         "0.032852166473165224"
        ],
        [
         "holiday",
         "0.004248119157850694",
         "0.00034025572149555257",
         "4.896778889625625e-06",
         "5",
         "0.004948710391243882",
         "0.003547527924457506"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>1.244051</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>1.119967e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>1.269229</td>\n",
       "      <td>1.218873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <td>0.325759</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>1.834428e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333218</td>\n",
       "      <td>0.318301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>0.320523</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>3.027268e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.328841</td>\n",
       "      <td>0.312206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>0.206686</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>1.641311e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.221246</td>\n",
       "      <td>0.192127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>0.133197</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>8.587677e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.125218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>1.059533e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.107430</td>\n",
       "      <td>0.094670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <td>0.060829</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>1.032534e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067619</td>\n",
       "      <td>0.054039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>0.040902</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>3.693006e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.038918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>0.035092</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>1.106089e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037331</td>\n",
       "      <td>0.032852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>4.896779e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.003548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance    stddev       p_value  n  p99_high   p99_low\n",
       "hour          1.244051  0.012228  1.119967e-09  5  1.269229  1.218873\n",
       "datetime      0.325759  0.003622  1.834428e-09  5  0.333218  0.318301\n",
       "temp          0.320523  0.004040  3.027268e-09  5  0.328841  0.312206\n",
       "workingday    0.206686  0.007071  1.641311e-07  5  0.221246  0.192127\n",
       "humidity      0.133197  0.003875  8.587677e-08  5  0.141176  0.125218\n",
       "atemp         0.101050  0.003099  1.059533e-07  5  0.107430  0.094670\n",
       "weather       0.060829  0.003298  1.032534e-06  5  0.067619  0.054039\n",
       "season        0.040902  0.000964  3.693006e-08  5  0.042886  0.038918\n",
       "windspeed     0.035092  0.001088  1.106089e-07  5  0.037331  0.032852\n",
       "holiday       0.004248  0.000340  4.896779e-06  5  0.004949  0.003548"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casual_predictor.feature_importance(casual_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce0f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Casual...\n",
      "Predicting Registered...\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting Casual...\")\n",
    "# Remember: The model outputs log1p(casual)\n",
    "pred_casual_log = casual_predictor.predict(test_data)\n",
    "\n",
    "print(\"Predicting Registered...\")\n",
    "pred_registered_log = registered_predictor.predict(test_data)\n",
    "\n",
    "# 3. Invert the Log Transform (expm1 = exp(x) - 1)\n",
    "pred_casual = np.expm1(pred_casual_log)\n",
    "pred_registered = np.expm1(pred_registered_log)\n",
    "\n",
    "# 4. Safety Clip (Models can theoretically predict negative numbers)\n",
    "pred_casual = np.maximum(pred_casual, 0)\n",
    "pred_registered = np.maximum(pred_registered, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_autogluon_best_quality.csv\n"
     ]
    }
   ],
   "source": [
    "final_count = pred_casual + pred_registered\n",
    "\n",
    "# 6. Save Submission\n",
    "submission = pd.read_csv(r\"resources\\bike-sharing-demand\\sampleSubmission.csv\")\n",
    "submission['count'] = final_count\n",
    "submission.to_csv(\"submission_autogluon_best_quality.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission_autogluon_best_quality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on Training Set...\n",
      "---------------------------------------------------\n",
      "Combined Train RMSLE: 0.16686\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "def evaluate_on_train(casual_predictor, registered_predictor, train_data):\n",
    "    \"\"\"\n",
    "    Calculates the combined RMSLE score on the training data.\n",
    "    \"\"\"\n",
    "    print(\"Generating predictions on Training Set...\")\n",
    "    \n",
    "    # 1. Predict (Output is in Log Space)\n",
    "    # AutoGluon automatically ignores the target column if present\n",
    "    pred_casual_log = casual_predictor.predict(train_data)\n",
    "    pred_registered_log = registered_predictor.predict(train_data)\n",
    "    \n",
    "    # 2. Inverse Transform (Log -> Count)\n",
    "    pred_casual = np.expm1(pred_casual_log)\n",
    "    pred_registered = np.expm1(pred_registered_log)\n",
    "    \n",
    "    # 3. Clip negatives (Safety)\n",
    "    pred_casual = np.maximum(pred_casual, 0)\n",
    "    pred_registered = np.maximum(pred_registered, 0)\n",
    "    \n",
    "    # 4. Combine\n",
    "    pred_total_count = pred_casual + pred_registered\n",
    "    \n",
    "    # 5. Get Actual Count\n",
    "    # We assume 'count' column exists in train_data. \n",
    "    # If not, reconstruct it from casual + registered\n",
    "    if 'count' in train_data.columns:\n",
    "        actual_count = train_data['count']\n",
    "    else:\n",
    "        actual_count = train_data['casual'] + train_data['registered']\n",
    "    \n",
    "    # 6. Calculate RMSLE\n",
    "    # RMSLE = sqrt(mean((log(p+1) - log(a+1))^2))\n",
    "    # Sklearn's mean_squared_log_error does the log part for us\n",
    "    rmsle = np.sqrt(mean_squared_log_error(actual_count, pred_total_count))\n",
    "    \n",
    "    print(f\"---------------------------------------------------\")\n",
    "    print(f\"Combined Train RMSLE: {rmsle:.5f}\")\n",
    "    print(f\"---------------------------------------------------\")\n",
    "    \n",
    "    return rmsle, pred_total_count\n",
    "\n",
    "# --- Usage ---\n",
    "# Make sure your predictors and train_data are loaded\n",
    "score, preds = evaluate_on_train(casual_predictor, registered_predictor, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd1a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
